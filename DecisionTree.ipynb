{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca78891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bot import get_historical_data\n",
    "import pandas as pd\n",
    "from binance.client import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, make_scorer, precision_score\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3067658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_costs = 0.0005\n",
    "\n",
    "# Start investment is EURO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Bitcoin prices at 5-minute intervals for the last 40 days\n",
    "symbol = 'BTCEUR'\n",
    "days = 10000\n",
    "\n",
    "bitcoin_data_hour = get_historical_data(symbol, Client.KLINE_INTERVAL_1HOUR, days)\n",
    "#bitcoin_data_5minute = get_historical_data(symbol, Client.KLINE_INTERVAL_5MINUTE, days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3342974",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_data_hour[\"pct\"] = bitcoin_data_hour[\"Close\"].pct_change().shift(-1)    #time shift ist WICHTIG! einer der häufigsten Fehler, wenn er vergessen wird\n",
    "#bitcoin_data_5minute[\"pct\"] = bitcoin_data_5minute[\"Close\"].pct_change().shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_data_hour.dropna(inplace=True)\n",
    "#bitcoin_data_5minute.dropna(inplace=True)\n",
    "\n",
    "df_hour = bitcoin_data_hour\n",
    "#df_5minute = bitcoin_data_5minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio(s: pd.Series):\n",
    "    sharpe = s.mean() / s.std()\n",
    "    print(s.mean(), s.std())\n",
    "    return sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9027a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion um zu zählen wie häufig ein buy Signal hinter einander auftritt\n",
    "def count_consecutive_ones(data: pd.DataFrame, signal_col: str):\n",
    "    new_column_name = signal_col + \"_count\"\n",
    "    \n",
    "    count = 0\n",
    "    counts = []\n",
    "    \n",
    "    for value in data[signal_col]:\n",
    "        if value == 1:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "        counts.append(count)\n",
    "    \n",
    "    data[new_column_name] = counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcddc4a7",
   "metadata": {},
   "source": [
    "### Indikatoren und Indexe berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ad3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OBV_berechnen(data:pd.DataFrame):\n",
    "    #benötigt ein DataFrame mit den Spalten \"4a. close (EUR)\" und \"5. volume\"\n",
    "    data[\"OBV\"] = (np.sign(data[\"Close\"].pct_change()) * data[\"Volume\"]).cumsum()\n",
    "    \n",
    "def SMA_berechnen(data:pd.DataFrame, intervall:int):\n",
    "    spalten_name = \"SMA_\"+str(intervall)\n",
    "    data[spalten_name] = data[\"Close\"].rolling(intervall).mean()\n",
    "    spalten_name_sig = \"SMA_\"+str(intervall)+\"_Sig\"\n",
    "    data[spalten_name_sig] = (data[\"Close\"]>data[spalten_name]).astype(int)\n",
    "    print(data[spalten_name_sig].mean())\n",
    "    count_consecutive_ones(data, spalten_name_sig)\n",
    "    \n",
    "def RSI_berechnen(data:pd.DataFrame, intervall:int):\n",
    "\n",
    "    spalten_name = \"RSI_\"+str(intervall)\n",
    "\n",
    "    # Bestimme die Preisänderung zum jeweiligen Zeitpunkt t-1\n",
    "    delta = data[\"Close\"].diff()\n",
    "\n",
    "    # Get rid of the first row, which has NaN values\n",
    "    delta = delta[1:]\n",
    "\n",
    "    # Calculate the gains and losses\n",
    "    up = delta.where(delta > 0, 0)\n",
    "    down = -delta.where(delta < 0, 0)\n",
    "\n",
    "    # Calculate the rolling average of the gains and losses\n",
    "    #window_size = 14 #als default\n",
    "    avg_gain = up.rolling(intervall).mean()\n",
    "    avg_loss = down.rolling(intervall).mean()\n",
    "\n",
    "    # Calculate the relative strength\n",
    "    rs = avg_gain / avg_loss\n",
    "\n",
    "    # Calculate the RSI\n",
    "    data[spalten_name] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "def EMA_berechnen(data: pd.DataFrame, intervall: int):\n",
    "    spalten_name = \"EMA_\" + str(intervall)\n",
    "    data[spalten_name] = data[\"Close\"].ewm(span=intervall, adjust=False).mean()\n",
    "    spalten_name_sig = \"EMA_\"+str(intervall)+\"_Sig\"\n",
    "    data[spalten_name_sig] = (data[\"Close\"]>data[spalten_name]).astype(int)\n",
    "    count_consecutive_ones(data, spalten_name_sig)\n",
    "\n",
    "def HMA_berechnen(data: pd.DataFrame, intervall: int):\n",
    "    spalten_name = \"HMA_\" + str(intervall)\n",
    "    half_length = int(intervall / 2)\n",
    "    sqrt_length = int(np.sqrt(intervall))\n",
    "\n",
    "    wma_half = data[\"Close\"].rolling(window=half_length).mean()\n",
    "    wma_full = data[\"Close\"].rolling(window=intervall).mean()\n",
    "\n",
    "    raw_hma = 2 * wma_half - wma_full\n",
    "    data[spalten_name] = raw_hma.rolling(window=sqrt_length).mean()\n",
    "    \n",
    "    spalten_name_sig = \"HMA_\"+str(intervall)+\"_Sig\"\n",
    "    data[spalten_name_sig] = (data[\"Close\"]>data[spalten_name]).astype(int)\n",
    "    count_consecutive_ones(data, spalten_name_sig)\n",
    "\n",
    "def MACD_berechnen(data: pd.DataFrame, fast_period: int = 12, slow_period: int = 26, signal_period: int = 9):\n",
    "    data[\"MACD\"] = data[\"Close\"].ewm(span=fast_period, adjust=False).mean() - data[\"Close\"].ewm(span=slow_period, adjust=False).mean()\n",
    "    data[\"MACD_Signal\"] = data[\"MACD\"].ewm(span=signal_period, adjust=False).mean()\n",
    "\n",
    "def Momentum_berechnen(data: pd.DataFrame, intervall: int):\n",
    "    spalten_name = \"Momentum_\" + str(intervall)\n",
    "    data[spalten_name] = data[\"Close\"].diff(intervall)\n",
    "\n",
    "def Stochastic_RSI_berechnen(data: pd.DataFrame, intervall: int):\n",
    "    spalten_name = \"StochRSI_\" + str(intervall)\n",
    "\n",
    "    delta = data[\"Close\"].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=intervall).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=intervall).mean()\n",
    "\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "\n",
    "    min_RSI = RSI.rolling(window=intervall).min()\n",
    "    max_RSI = RSI.rolling(window=intervall).max()\n",
    "\n",
    "    data[spalten_name] = (RSI - min_RSI) / (max_RSI - min_RSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b7efc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indicators = []\n",
    "dt_indicators = []\n",
    "OBV_berechnen(df_hour)\n",
    "MACD_berechnen(df_hour)\n",
    "dt_indicators.extend([f'OBV', f'MACD'])\n",
    "for i in [50, 500]:#[5, 10, 20, 50, 100, 500, 1000]:\n",
    "    SMA_berechnen(df_hour, i)\n",
    "    RSI_berechnen(df_hour, i)\n",
    "    EMA_berechnen(df_hour, i)\n",
    "    HMA_berechnen(df_hour, i)\n",
    "    Momentum_berechnen(df_hour, i)\n",
    "    Stochastic_RSI_berechnen(df_hour, i)\n",
    "    indicators.extend([f\"RSI_{i}\", f\"EMA_{i}\", f\"HMA_{i}\", f\"Momentum_{i}\", f\"StochRSI_{i}\"])\n",
    "    dt_indicators.extend([f\"RSI_{i}\", f\"SMA_{i}_Sig\", f\"EMA_{i}_Sig\", f\"HMA_{i}_Sig\", f\"Momentum_{i}\", f\"StochRSI_{i}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58196213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#berechnet performance für das gewollte Zeitfenster\n",
    "def create_labels(data: pd.DataFrame, window: int):\n",
    "    data[\"future_return\"] = data[\"Close\"].shift(-window) / data[\"Close\"] - 1\n",
    "    data[\"label\"] = (data[\"future_return\"] > 0.001).astype(int)\n",
    "    data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0768d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "def train_decision_tree(data: pd.DataFrame, features: list, target: str):\n",
    "    # Indizes zurücksetzen, um Probleme mit der Indizierung zu vermeiden\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    # Aufteilen der Daten in Trainings- und Testdaten\n",
    "    train_size = int(len(data) * 0.8)\n",
    "    train_data = data.iloc[:train_size]\n",
    "    test_data = data.iloc[train_size:]\n",
    "    X_train = train_data[features]\n",
    "    X_test = test_data[features]\n",
    "    y_train = train_data[target]\n",
    "    y_test = test_data[target]\n",
    "\n",
    "    # Definiere den Parameterbereich für GridSearch\n",
    "    param_grid = {\n",
    "        #'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [5, 10, 20],\n",
    "        #'min_samples_split': [2, 5, 10],\n",
    "        #'min_samples_leaf': [5, 10, 20, 30],\n",
    "        #'max_features': [None, 'sqrt', 'log2']\n",
    "    }\n",
    "    \n",
    "    # Definiere den Precision-Scorer\n",
    "    precision_scorer = make_scorer(precision_score, pos_label=1)\n",
    "    \n",
    "    # Initialisiere den GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
    "                               param_grid=param_grid,\n",
    "                                cv=3,  # Anzahl der Cross-Validation-Folds\n",
    "                                scoring=precision_scorer,  # Bewertungskriterium\n",
    "                                n_jobs=-1,  # Nutze alle verfügbaren CPU-Kerne\n",
    "                                verbose=2)  # Ausgabe von Fortschrittsinformationen\n",
    "\n",
    "     # Führe GridSearch aus\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Ausgabe der besten Parameter\n",
    "    print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "    \n",
    "    # Modell mit den besten Parametern\n",
    "    best_clf = grid_search.best_estimator_\n",
    "    \n",
    "    # Vorhersagen auf Testdaten\n",
    "    #y_pred = best_clf.predict(X_test)\n",
    "    \n",
    "    #best_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "    #best_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get the predicted probabilities\n",
    "    y_pred_proba = best_clf.predict_proba(X_test)\n",
    "    #print(y_pred_proba.shape)\n",
    "    # Set y_pred to 1 if the probability of class 1 is greater than 0.8, otherwise set it to 0\n",
    "    threshold = 0.9\n",
    "    y_pred = (y_pred_proba[:, 1] > threshold).astype(int)\n",
    "    #print(y_pred.shape)\n",
    "    #print(y_test)\n",
    "    #print(y_pred_proba)\n",
    "    #print(classification_report(y_test, y_pred))\n",
    "    #y_pred = clf.predict(X_test)\n",
    "    # Berechne die Sharpe Ratio\n",
    "    \n",
    "    test_returns = data.loc[X_test.index, \"pct\"]\n",
    "    print(f'sharpe test {sharpe_ratio(test_returns)}')\n",
    "    # Initialize strat_returns with test_returns values\n",
    "    strat_returns = test_returns.copy()\n",
    "    # Set the rows in strat_returns to 0 where y_pred equals 0\n",
    "    strat_returns[y_pred == 0] = 0\n",
    "    sharpe = sharpe_ratio(strat_returns)\n",
    "    print(f\"Sharpe Ratio: {sharpe}\")\n",
    "    \n",
    "    # Performance DataFrame erstellen\n",
    "    PF = pd.DataFrame(data[\"pct\"].iloc[X_test.index])\n",
    "    PF[\"pred\"] = y_pred\n",
    "    PF[\"strategy_returns\"] = PF[\"pred\"] * PF[\"pct\"]\n",
    "    PF[\"cumulative_strategy_returns\"] = (PF[\"strategy_returns\"] + 1).cumprod()\n",
    "\n",
    "    PF[\"benchmark_returns\"] = PF[\"pct\"]\n",
    "    PF[\"cumulative_benchmark_returns\"] = (PF[\"benchmark_returns\"] + 1).cumprod()\n",
    "    \n",
    "    # Plotten der Ergebnisse\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(PF[\"cumulative_strategy_returns\"], label=\"Strategy Returns\")\n",
    "    plt.plot(PF[\"cumulative_benchmark_returns\"], label=\"Benchmark Returns\")\n",
    "    plt.title(\"Cumulative Returns\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Cumulative Returns\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return best_clf, sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae3904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_indicators(data: pd.DataFrame, indicators: list, target: str):\n",
    "    best_sharpe = -np.inf\n",
    "    best_combination = None\n",
    "    best_model = None\n",
    "\n",
    "    for r in range(1, len(indicators) + 1):\n",
    "        for combo in combinations(indicators, r):\n",
    "            if len(combo)<4:\n",
    "                continue\n",
    "            print(combo)\n",
    "            features = list(combo)\n",
    "            clf, sharpe = train_decision_tree(data, features, target)\n",
    "            if sharpe > best_sharpe:\n",
    "                best_sharpe = sharpe\n",
    "                best_combination = combo\n",
    "                best_model = clf\n",
    "\n",
    "    print(f\"Best Sharpe Ratio: {best_sharpe}\")\n",
    "    print(f\"Best Indicator Combination: {best_combination}\")\n",
    "\n",
    "    return best_model, best_combination, best_sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d957f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Labels erstellen\n",
    "create_labels(df_hour, window=24)\n",
    "\n",
    "#dt_indicators.extend([f'EMA_{5}', f'EMA_{50}', f'EMA_{500}'])\n",
    "# Liste der Indikatoren\n",
    "features = dt_indicators#[\"SMA_50_Sig\", \"SMA_500_Sig\", \"HMA_50_Sig\", \"EMA_50_Sig\", \"EMA_500_Sig\", \"EMA_5_Sig\"]#[\"OBV\", \"RSI_5\", \"RSI_10\"]#, \"RSI_50\", \"RSI_50\", \"MACD\", \"MACD_Signal\", \"Momentum_10\", \"StochRSI_10\", \"StochRSI_20\", \"StochRSI_50\"]\n",
    "\n",
    "# Beste Indikatoren finden\n",
    "best_model, best_combination, best_sharpe = find_best_indicators(df_hour, features, \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ed0227",
   "metadata": {},
   "source": [
    "man könnte probieren, zu zählen wie häufig die Buy-Signale bei den Averages hintereinander aufkommen und das dann in den DT übergeben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b7938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc19814c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
