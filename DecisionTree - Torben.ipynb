{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bot import get_historical_data\n",
    "import pandas as pd\n",
    "from binance.client import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, make_scorer, precision_score\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ff1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_costs = 0.0005\n",
    "\n",
    "# Start investment is EURO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc85756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Bitcoin prices at 5-minute intervals for the last 40 days\n",
    "symbol = 'BTCEUR'\n",
    "days = 10000\n",
    "\n",
    "bitcoin_data_hour = get_historical_data(symbol, Client.KLINE_INTERVAL_1HOUR, days)\n",
    "#bitcoin_data_5minute = get_historical_data(symbol, Client.KLINE_INTERVAL_5MINUTE, days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_data_hour[\"pct\"] = bitcoin_data_hour[\"Close\"].pct_change().shift(-1)    #time shift ist WICHTIG! einer der häufigsten Fehler, wenn er vergessen wird\n",
    "#bitcoin_data_5minute[\"pct\"] = bitcoin_data_5minute[\"Close\"].pct_change().shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_data_hour.dropna(inplace=True)\n",
    "#bitcoin_data_5minute.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4f5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_data_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a81ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour = bitcoin_data_hour.copy()\n",
    "#df_5minute = bitcoin_data_5minute\n",
    "df_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio(s: pd.Series):\n",
    "    sharpe = s.mean() / s.std()\n",
    "    print(s.mean(), s.std())\n",
    "    return sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec6741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion um zu zählen wie häufig ein buy Signal hinter einander auftritt\n",
    "def count_consecutive_ones(data: pd.DataFrame, signal_col: str):\n",
    "    new_column_name = signal_col + \"_count\"\n",
    "    \n",
    "    count = 0\n",
    "    counts = []\n",
    "    \n",
    "    for value in data[signal_col]:\n",
    "        if value == 1:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "        counts.append(count)\n",
    "    \n",
    "    data[new_column_name] = counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db21c4a7",
   "metadata": {},
   "source": [
    "### Indikatoren und Indexe berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e200ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OBV_berechnen(data:pd.DataFrame):\n",
    "    #benötigt ein DataFrame mit den Spalten \"4a. close (EUR)\" und \"5. volume\"\n",
    "    data[\"OBV\"] = (np.sign(data[\"Close\"].pct_change()) * data[\"Volume\"]).cumsum()\n",
    "    \n",
    "def SMA_berechnen(data:pd.DataFrame, intervall:int):\n",
    "    spalten_name = \"SMA_\"+str(intervall)\n",
    "    data[spalten_name] = data[\"Close\"].rolling(intervall).mean()\n",
    "    spalten_name_sig = \"SMA_\"+str(intervall)+\"_Sig\"\n",
    "    data[spalten_name_sig] = (data[\"Close\"]>data[spalten_name]).astype(int)\n",
    "    print(data[spalten_name_sig].mean())\n",
    "    count_consecutive_ones(data, spalten_name_sig)\n",
    "    \n",
    "def RSI_berechnen(data:pd.DataFrame, intervall:int):\n",
    "\n",
    "    spalten_name = \"RSI_\"+str(intervall)\n",
    "\n",
    "    # Bestimme die Preisänderung zum jeweiligen Zeitpunkt t-1\n",
    "    delta = data[\"Close\"].diff()\n",
    "\n",
    "    # Get rid of the first row, which has NaN values\n",
    "    delta = delta[1:]\n",
    "\n",
    "    # Calculate the gains and losses\n",
    "    up = delta.where(delta > 0, 0)\n",
    "    down = -delta.where(delta < 0, 0)\n",
    "\n",
    "    # Calculate the rolling average of the gains and losses\n",
    "    #window_size = 14 #als default\n",
    "    avg_gain = up.rolling(intervall).mean()\n",
    "    avg_loss = down.rolling(intervall).mean()\n",
    "\n",
    "    # Calculate the relative strength\n",
    "    rs = avg_gain / avg_loss\n",
    "\n",
    "    # Calculate the RSI\n",
    "    data[spalten_name] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "def EMA_berechnen(data: pd.DataFrame, intervall: int):\n",
    "    spalten_name = \"EMA_\" + str(intervall)\n",
    "    data[spalten_name] = data[\"Close\"].ewm(span=intervall, adjust=False).mean()\n",
    "    spalten_name_sig = \"EMA_\"+str(intervall)+\"_Sig\"\n",
    "    data[spalten_name_sig] = (data[\"Close\"]>data[spalten_name]).astype(int)\n",
    "    count_consecutive_ones(data, spalten_name_sig)\n",
    "\n",
    "def HMA_berechnen(data: pd.DataFrame, intervall: int):\n",
    "    spalten_name = \"HMA_\" + str(intervall)\n",
    "    half_length = int(intervall / 2)\n",
    "    sqrt_length = int(np.sqrt(intervall))\n",
    "\n",
    "    wma_half = data[\"Close\"].rolling(window=half_length).mean()\n",
    "    wma_full = data[\"Close\"].rolling(window=intervall).mean()\n",
    "\n",
    "    raw_hma = 2 * wma_half - wma_full\n",
    "    data[spalten_name] = raw_hma.rolling(window=sqrt_length).mean()\n",
    "    \n",
    "    spalten_name_sig = \"HMA_\"+str(intervall)+\"_Sig\"\n",
    "    data[spalten_name_sig] = (data[\"Close\"]>data[spalten_name]).astype(int)\n",
    "    count_consecutive_ones(data, spalten_name_sig)\n",
    "\n",
    "def MACD_berechnen(data: pd.DataFrame, fast_period: int = 12, slow_period: int = 26, signal_period: int = 9):\n",
    "    data[\"MACD\"] = data[\"Close\"].ewm(span=fast_period, adjust=False).mean() - data[\"Close\"].ewm(span=slow_period, adjust=False).mean()\n",
    "    data[\"MACD_Signal\"] = data[\"MACD\"].ewm(span=signal_period, adjust=False).mean()\n",
    "\n",
    "def Momentum_berechnen(data: pd.DataFrame, intervall: int):\n",
    "    spalten_name = \"Momentum_\" + str(intervall)\n",
    "    data[spalten_name] = data[\"Close\"].diff(intervall)\n",
    "\n",
    "def Stochastic_RSI_berechnen(data: pd.DataFrame, intervall: int):\n",
    "    spalten_name = \"StochRSI_\" + str(intervall)\n",
    "\n",
    "    delta = data[\"Close\"].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=intervall).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=intervall).mean()\n",
    "\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "\n",
    "    min_RSI = RSI.rolling(window=intervall).min()\n",
    "    max_RSI = RSI.rolling(window=intervall).max()\n",
    "\n",
    "    data[spalten_name] = (RSI - min_RSI) / (max_RSI - min_RSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc1103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indicators = []\n",
    "dt_indicators = []\n",
    "OBV_berechnen(df_hour)\n",
    "MACD_berechnen(df_hour)\n",
    "dt_indicators.extend([f'MACD_Signal'])\n",
    "for i in [5, 10, 24, 50, 100, 500, 1000]:\n",
    "    SMA_berechnen(df_hour, i)\n",
    "    RSI_berechnen(df_hour, i)\n",
    "    EMA_berechnen(df_hour, i)\n",
    "    HMA_berechnen(df_hour, i)\n",
    "    Momentum_berechnen(df_hour, i)\n",
    "    Stochastic_RSI_berechnen(df_hour, i)\n",
    "    indicators.extend([f\"RSI_{i}\", f\"EMA_{i}\", f\"HMA_{i}\", f\"Momentum_{i}\", f\"StochRSI_{i}\"])\n",
    "    dt_indicators.extend([f\"RSI_{i}\", f\"SMA_{i}_Sig\", f\"EMA_{i}_Sig\",# f\"HMA_{i}_Sig\", \n",
    "                          f\"Momentum_{i}\"#, f\"StochRSI_{i}\"\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead80934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#berechnet performance für das gewollte Zeitfenster\n",
    "def create_labels(data: pd.DataFrame, window: int):\n",
    "    data[\"future_return\"] = data[\"Close\"].shift(-window) / data[\"Close\"] - 1\n",
    "    data[\"label\"] = (data[\"future_return\"] > 0.00).astype(int)\n",
    "    data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666dfa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "def train_decision_tree(data: pd.DataFrame, features: list, target: str, threshold: float):\n",
    "    transaction_cost = 0.0005\n",
    "    # Indizes zurücksetzen, um Probleme mit der Indizierung zu vermeiden\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    # Aufteilen der Daten in Trainings- und Testdaten\n",
    "    train_size = int(len(data) * 0.8)\n",
    "    train_data = data.iloc[:train_size]\n",
    "    test_data = data.iloc[train_size:]\n",
    "    X_train = train_data[features]\n",
    "    X_test = test_data[features]\n",
    "    y_train = train_data[target]\n",
    "    y_test = test_data[target]\n",
    "\n",
    "    # Definiere den Parameterbereich für GridSearch\n",
    "    param_grid = {\n",
    "        #'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [5, 10, 20, 30],\n",
    "        #'min_samples_split': [2, 5, 10],\n",
    "        #'min_samples_leaf': [5, 10, 20, 30],\n",
    "        #'max_features': [None, 'sqrt', 'log2']\n",
    "    }\n",
    "    \n",
    "    # Definiere den Precision-Scorer\n",
    "    precision_scorer = make_scorer(precision_score, pos_label=1)\n",
    "    \n",
    "    # Initialisiere den GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
    "                               param_grid=param_grid,\n",
    "                                cv=3,  # Anzahl der Cross-Validation-Folds\n",
    "                                scoring=precision_scorer,  # Bewertungskriterium\n",
    "                                n_jobs=-1,  # Nutze alle verfügbaren CPU-Kerne\n",
    "                                verbose=2)  # Ausgabe von Fortschrittsinformationen\n",
    "\n",
    "     # Führe GridSearch aus\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Ausgabe der besten Parameter\n",
    "    print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "    \n",
    "    # Modell mit den besten Parametern\n",
    "    best_clf = grid_search.best_estimator_\n",
    "    \n",
    "    # Vorhersagen auf Testdaten\n",
    "    #y_pred = best_clf.predict(X_test)\n",
    "    \n",
    "    #best_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "    #best_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get the predicted probabilities\n",
    "    y_pred_proba = best_clf.predict_proba(X_test)\n",
    "    #print(y_pred_proba.shape)\n",
    "    # Set y_pred to 1 if the probability of class 1 is greater than 0.8, otherwise set it to 0\n",
    "    #threshold = 0.5\n",
    "    y_pred = (y_pred_proba[:, 1] > threshold).astype(int)\n",
    "    #print(y_pred.shape)\n",
    "    #print(y_test)\n",
    "    #print(y_pred_proba)\n",
    "    #print(classification_report(y_test, y_pred))\n",
    "    #y_pred = clf.predict(X_test)\n",
    "    # Berechne die Sharpe Ratio\n",
    "    \n",
    "    test_returns = data.loc[X_test.index, \"pct\"]\n",
    "    print(f'sharpe test {sharpe_ratio(test_returns)}')\n",
    "    # Initialize strat_returns with test_returns values\n",
    "    strat_returns = test_returns.copy()\n",
    "    # Set the rows in strat_returns to 0 where y_pred equals 0\n",
    "    strat_returns[y_pred == 0] = 0\n",
    "    \n",
    "    # Calculate transaction costs: a cost occurs whenever there is a change in the position (buy/sell)\n",
    "    positions = np.diff(np.concatenate([[0], y_pred]))  # Calculate position changes\n",
    "    transaction_costs = np.abs(positions) * transaction_cost  # Apply transaction costs\n",
    "    #print(strat_returns)\n",
    "    sharpe = sharpe_ratio(strat_returns)\n",
    "    print(f\"Sharpe Ratio without costs: {sharpe}\")\n",
    "    strat_returns -= transaction_costs  # Deduct transaction costs from strategy returns\n",
    "    #print(strat_returns)\n",
    "    print(f\"number of transactions {np.sum(np.abs(positions))}\")\n",
    "    #print(f\"Shape of positions: {positions.shape}\")\n",
    "    #print(f\"Shape of y_pred: {y_pred.shape}\")\n",
    "    sharpe = sharpe_ratio(strat_returns)\n",
    "    print(f\"Sharpe Ratio with costs: {sharpe}\")\n",
    "    \n",
    "    # Performance DataFrame erstellen\n",
    "    PF = pd.DataFrame(data[\"pct\"].iloc[X_test.index])\n",
    "    PF[\"pred\"] = y_pred\n",
    "    PF[\"strategy_returns\"] = PF[\"pred\"] * PF[\"pct\"]\n",
    "    PF[\"cumulative_strategy_returns\"] = (PF[\"strategy_returns\"] + 1).cumprod()\n",
    "\n",
    "    PF[\"benchmark_returns\"] = PF[\"pct\"]\n",
    "    PF[\"cumulative_benchmark_returns\"] = (PF[\"benchmark_returns\"] + 1).cumprod()\n",
    "    \n",
    "    # Calculate transaction indices\n",
    "    transaction_indices = np.where(np.abs(positions) > 0)[0]\n",
    "    \n",
    "    # Adjust transaction_indices to match PF index\n",
    "    transaction_indices = transaction_indices[transaction_indices < len(PF)]\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(PF[\"cumulative_strategy_returns\"], label=\"Strategy Returns\")\n",
    "    plt.plot(PF[\"cumulative_benchmark_returns\"], label=\"Benchmark Returns\")\n",
    "    \n",
    "    # Add dots where transactions occur\n",
    "    plt.scatter(PF.index[transaction_indices], PF[\"cumulative_strategy_returns\"].iloc[transaction_indices],\n",
    "                color='red', marker='o', label='Transactions')\n",
    "    \n",
    "    plt.title(\"Cumulative Returns with Transactions\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Cumulative Returns\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return best_clf, sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85623973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_indicators(data: pd.DataFrame, indicators: list, target: str, threshold: float):\n",
    "    best_sharpe = -np.inf\n",
    "    best_combination = None\n",
    "    best_model = None\n",
    "\n",
    "    for r in range(1, len(indicators) + 1):\n",
    "        for combo in combinations(indicators, r):\n",
    "            if len(combo)<5:\n",
    "                continue\n",
    "            print(combo)\n",
    "            features = list(combo)\n",
    "            clf, sharpe = train_decision_tree(data, features, target, threshold)\n",
    "            if sharpe > best_sharpe:\n",
    "                best_sharpe = sharpe\n",
    "                best_combination = combo\n",
    "                best_model = clf\n",
    "\n",
    "    print(f\"Best Sharpe Ratio: {best_sharpe}\")\n",
    "    print(f\"Best Indicator Combination: {best_combination}\")\n",
    "\n",
    "    return best_model, best_combination, best_sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0080eb6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Labels erstellen\n",
    "create_labels(df_hour, window=1)\n",
    "\n",
    "df_hour.dropna()\n",
    "\n",
    "print(df_hour.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db996d6a",
   "metadata": {},
   "source": [
    "### threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb61d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dt_indicators.extend([f'EMA_{5}', f'EMA_{50}', f'EMA_{500}'])\n",
    "# Liste der Indikatoren\n",
    "features = [\"SMA_100_Sig\", \"EMA_100\", \"SMA_500\", \"EMA_500\", \"Momentum_100\", \"Momentum_500\", \"RSI_100\", \"RSI_500\", \"SMA_100_Sig_count\", \"EMA_100_Sig_count\"]#[\"OBV\", \"RSI_5\", \"RSI_10\"]#, \"RSI_50\", \"RSI_50\", \"MACD\", \"MACD_Signal\", \"Momentum_10\", \"StochRSI_10\", \"StochRSI_20\", \"StochRSI_50\"]\n",
    "\n",
    "\n",
    "# Beste Indikatoren finden\n",
    "best_model, best_combination, best_sharpe = find_best_indicators(df_hour, features, \"label\", threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8332a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Sharpe Ratio: 0.03856916901080272\n",
    "# Best Indicator Combination: ('SMA_100_Sig', 'EMA_100', 'Momentum_100', 'Momentum_500', 'RSI_500')\n",
    "# Beste Parameter: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 10}\n",
    "# 9.206389028191728e-05 0.005648386026191348\n",
    "# sharpe test 0.01629914985537826\n",
    "# 5.4330651286781826e-05 0.003247057379067564\n",
    "# Sharpe Ratio: 0.016732273238233814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f9eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt_indicators.extend([f'EMA_{5}', f'EMA_{50}', f'EMA_{500}'])\n",
    "# Liste der Indikatoren\n",
    "features = [\"SMA_100_Sig\", \"EMA_100\", \"SMA_500\", \"EMA_500\", \"SMA_100_Sig_count\", \"EMA_100_Sig_count\", \"Momentum_100\", \"Momentum_500\", \"RSI_500\"]#[\"OBV\", \"RSI_5\", \"RSI_10\"]#, \"RSI_50\", \"RSI_50\", \"MACD\", \"MACD_Signal\", \"Momentum_10\", \"StochRSI_10\", \"StochRSI_20\", \"StochRSI_50\"]\n",
    "\n",
    "\n",
    "# Beste Indikatoren finden\n",
    "best_model, best_combination, best_sharpe = find_best_indicators(df_hour, features, \"label\", threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e7a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Sharpe Ratio: 0.038928980946217204\n",
    "# Best Indicator Combination: ('SMA_100_Sig', 'EMA_100', 'SMA_500', 'EMA_500', 'SMA_100_Sig_count', 'RSI_500')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3613dd8c",
   "metadata": {},
   "source": [
    "### threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096b920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt_indicators.extend([f'EMA_{5}', f'EMA_{50}', f'EMA_{500}'])\n",
    "# Liste der Indikatoren\n",
    "features = [\"SMA_100_Sig\", \"EMA_100\", \"SMA_500\", \"EMA_500\", \"SMA_100_Sig_count\", \"EMA_100_Sig_count\", \"Momentum_100\", \"Momentum_500\", \"RSI_500\"]#[\"OBV\", \"RSI_5\", \"RSI_10\"]#, \"RSI_50\", \"RSI_50\", \"MACD\", \"MACD_Signal\", \"Momentum_10\", \"StochRSI_10\", \"StochRSI_20\", \"StochRSI_50\"]\n",
    "\n",
    "\n",
    "# Beste Indikatoren finden\n",
    "best_model, best_combination, best_sharpe = find_best_indicators(df_hour, features, \"label\", threshold = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7faa462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Sharpe Ratio: 0.02696321379463089\n",
    "# Best Indicator Combination: ('SMA_100_Sig', 'EMA_100', 'SMA_500', 'EMA_500', 'SMA_100_Sig_count', 'RSI_500')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4305d3",
   "metadata": {},
   "source": [
    "man könnte probieren, zu zählen wie häufig die Buy-Signale bei den Averages hintereinander aufkommen und das dann in den DT übergeben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13e49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3237b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour[\"Signals\"] = (df_hour[\"SMA_5_Sig\"] & df_hour[\"SMA_10_Sig\"] & df_hour[\"SMA_50_Sig\"] & df_hour[\"SMA_100_Sig\"] \n",
    "                    & df_hour[\"EMA_5_Sig\"] & df_hour[\"EMA_10_Sig\"] & df_hour[\"EMA_50_Sig\"] & df_hour[\"EMA_100_Sig\"] \n",
    "                    & df_hour[\"HMA_5_Sig\"] & df_hour[\"HMA_10_Sig\"] & df_hour[\"HMA_50_Sig\"] & df_hour[\"HMA_100_Sig\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88760456",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_hour[\"Signals_pct\"] = df_hour[\"SMA_1680_Sig\"] * df_hour[\"pct\"]\n",
    "df_hour[\"Signals_PF\"] = (df_hour[\"Signals_pct\"] +1).cumprod()\n",
    "\n",
    "#Benchmark\n",
    "df_hour[\"PF_BM\"] =  df_hour[\"pct\"]\n",
    "df_hour[\"myPF_BM\"] = (df_hour[\"PF_BM\"] +1).cumprod()\n",
    "\n",
    "df_hour[[\"myPF_BM\",\"Signals_PF\"]].plot(figsize=(16,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5233a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_data = data.iloc[:train_size]\n",
    "test_data = data.iloc[train_size:]\n",
    "X_train = train_data[features]\n",
    "X_test = test_data[features]\n",
    "y_train = train_data[target]\n",
    "y_test = test_data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3652f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour[[\"Close\",\"SMA_1680\",\"SMA_100\"]].plot(figsize=(16,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eae436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Open time' is a datetime index\n",
    "df_hour['Close time'] = pd.to_datetime(df_hour['Close time'])\n",
    "\n",
    "# Set 'Open time' as the DataFrame index\n",
    "df_hour.set_index('Close time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b415fc2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Iterate over 3-month periods\n",
    "start_date = df_hour.index.min()\n",
    "end_date = df_hour.index.max()\n",
    "\n",
    "# Create plots for each 3-month period\n",
    "while start_date < end_date:\n",
    "    # Define the end date of the current 3-month period\n",
    "    current_end_date = start_date + pd.DateOffset(months=3)\n",
    "    \n",
    "    # Slice the data for the current 3-month period\n",
    "    df_slice = df_hour[(df_hour.index >= start_date) & (df_hour.index < current_end_date)]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    df_slice[[\"Close\", \"SMA_1680\", \"SMA_100\", \"EMA_100\", \"EMA_500\", \"SMA_50\", \"EMA_50\"]].plot(ax=plt.gca())\n",
    "    plt.title(f'Close Price and SMAs from {start_date.date()} to {current_end_date.date()}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Move to the next 3-month period\n",
    "    start_date = current_end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a4d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the VIX ticker symbol\n",
    "ticker = '^VIX'\n",
    "\n",
    "# Fetch data from Yahoo Finance\n",
    "data = yf.download(ticker, interval='1h', start='2024-08-01', end='2024-08-10')\n",
    "\n",
    "# Print the first few rows of the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a344e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Bitcoin ticker symbol\n",
    "ticker = 'BTC-EUR'\n",
    "\n",
    "# Fetch data from Yahoo Finance\n",
    "data = yf.download(ticker, interval='1h', start='2024-08-01', end='2024-08-10')\n",
    "\n",
    "# Calculate returns\n",
    "data['Return'] = data['Close'].pct_change()\n",
    "\n",
    "# Calculate rolling volatility (standard deviation of returns)\n",
    "data['Volatility'] = data['Return'].rolling(window=24).std() * np.sqrt(24)\n",
    "\n",
    "# Plot the volatility\n",
    "data['Volatility'].plot(title='Hourly Bitcoin Volatility')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be803c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
